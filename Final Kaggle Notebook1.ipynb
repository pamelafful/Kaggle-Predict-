{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C://Users//pamela.afful//Desktop//KaggleGithubFolder//train.csv')\n",
    "test=pd.read_csv('C://Users//pamela.afful//Desktop//KaggleGithubFolder//test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "handles=r'@\\w+'\n",
    "generic_urls=r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Takes in text and precocesses the data returning clean text\n",
    "'''\n",
    "def preprocess(df_text):\n",
    "    df_text=df_text.lower()\n",
    "    df_text= re.sub(generic_urls, '', df_text)\n",
    "    df_text= re.sub(handles, '', df_text)\n",
    "    df_text = re.sub('<[^>]*>', '', df_text)\n",
    "    tokenized_list = nltk.word_tokenize(df_text)\n",
    "    porter_stem = PorterStemmer()#(language='english')\n",
    "    #lemmatizer=WordNetLemmatizer() \n",
    "    stemed_list=[]\n",
    "    for i in tokenized_list:\n",
    "        stemed_list.append(porter_stem.stem(i))\n",
    "    stop_words=set(stopwords.words('english')) \n",
    "    cleaned_list=[i for i in stemed_list if i not in stop_words]\n",
    "    cleaned_list= [i for i in cleaned_list if len(i)>2]\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    return ' '.join(cleaned_list)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned message']=data['message'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>cleaned message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief doe n't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evid anthropogen global warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>research say three year act climat chang befor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmak wire 2016 pivot year war climat chang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>2016 racist sexist climat chang deni bigot lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ezlusztig: They took down the material on ...</td>\n",
       "      <td>22001</td>\n",
       "      <td>took materi global warm lgbt right health care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @washingtonpost: How climate change could b...</td>\n",
       "      <td>17856</td>\n",
       "      <td>climat chang could break 200-million-year-old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0</td>\n",
       "      <td>notiven: RT: nytimesworld :What does Trump act...</td>\n",
       "      <td>384248</td>\n",
       "      <td>notiven nytimesworld doe trump actual believ c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @sara8smiles: Hey liberals the climate chan...</td>\n",
       "      <td>819732</td>\n",
       "      <td>hey liber climat chang crap hoax tie agenda203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Chet_Cannon: .@kurteichenwald's 'climate c...</td>\n",
       "      <td>806319</td>\n",
       "      <td>'climat chang equat screenshot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "0              1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1              1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2              2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3              1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4              1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "...          ...                                                ...      ...   \n",
       "15814          1  RT @ezlusztig: They took down the material on ...    22001   \n",
       "15815          2  RT @washingtonpost: How climate change could b...    17856   \n",
       "15816          0  notiven: RT: nytimesworld :What does Trump act...   384248   \n",
       "15817         -1  RT @sara8smiles: Hey liberals the climate chan...   819732   \n",
       "15818          0  RT @Chet_Cannon: .@kurteichenwald's 'climate c...   806319   \n",
       "\n",
       "                                         cleaned message  \n",
       "0      polyscimajor epa chief doe n't think carbon di...  \n",
       "1                 like lack evid anthropogen global warm  \n",
       "2      research say three year act climat chang befor...  \n",
       "3       todayinmak wire 2016 pivot year war climat chang  \n",
       "4      2016 racist sexist climat chang deni bigot lea...  \n",
       "...                                                  ...  \n",
       "15814  took materi global warm lgbt right health care...  \n",
       "15815  climat chang could break 200-million-year-old ...  \n",
       "15816  notiven nytimesworld doe trump actual believ c...  \n",
       "15817  hey liber climat chang crap hoax tie agenda203...  \n",
       "15818                     'climat chang equat screenshot  \n",
       "\n",
       "[15819 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data and Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['cleaned message']\n",
    "y=data['sentiment']\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2,max_df=0.80)\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=0.30,shuffle=True, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884901839748492"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr=LogisticRegression(multi_class='multinomial',max_iter=250)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred=lr.predict(X_train)\n",
    "metrics.f1_score(y_train, y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6241491092071062"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=lr.predict(X_val)\n",
    "metrics.f1_score(y_val, y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=test.copy()\n",
    "test1['cleaned message']=test1['message'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "      <td>europ look china make sure alon fight climat c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>0</td>\n",
       "      <td>combin thi poll staffer climat chang women rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "      <td>scari unimpeach evid climat chang alreadi itst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "      <td>putin got jill trump doe n't believ climat cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "      <td>1</td>\n",
       "      <td>'femal orgasm caus global warm -sarcast republ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>RT @BrittanyBohrer: Brb, writing a poem about ...</td>\n",
       "      <td>895714</td>\n",
       "      <td>1</td>\n",
       "      <td>brb write poem climat chang climatechang scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>2016: the year climate change came home: Durin...</td>\n",
       "      <td>875167</td>\n",
       "      <td>1</td>\n",
       "      <td>2016 year climat chang came home dure hottest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>RT @loop_vanuatu: Pacific countries positive a...</td>\n",
       "      <td>78329</td>\n",
       "      <td>1</td>\n",
       "      <td>pacif countri posit fiji lead global climat ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>RT @xanria_00018: You’re so hot, you must be t...</td>\n",
       "      <td>867455</td>\n",
       "      <td>0</td>\n",
       "      <td>hot must caus global warm aldublaboroflov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>RT @chloebalaoing: climate change is a global ...</td>\n",
       "      <td>470892</td>\n",
       "      <td>2</td>\n",
       "      <td>climat chang global issu onli get wors eat pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  tweetid  sentiment  \\\n",
       "0      Europe will now be looking to China to make su...   169760          1   \n",
       "1      Combine this with the polling of staffers re c...    35326          0   \n",
       "2      The scary, unimpeachable evidence that climate...   224985          1   \n",
       "3      @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263          1   \n",
       "4      RT @FakeWillMoore: 'Female orgasms cause globa...   872928          1   \n",
       "...                                                  ...      ...        ...   \n",
       "10541  RT @BrittanyBohrer: Brb, writing a poem about ...   895714          1   \n",
       "10542  2016: the year climate change came home: Durin...   875167          1   \n",
       "10543  RT @loop_vanuatu: Pacific countries positive a...    78329          1   \n",
       "10544  RT @xanria_00018: You’re so hot, you must be t...   867455          0   \n",
       "10545  RT @chloebalaoing: climate change is a global ...   470892          2   \n",
       "\n",
       "                                         cleaned message  \n",
       "0      europ look china make sure alon fight climat c...  \n",
       "1      combin thi poll staffer climat chang women rig...  \n",
       "2      scari unimpeach evid climat chang alreadi itst...  \n",
       "3      putin got jill trump doe n't believ climat cha...  \n",
       "4      'femal orgasm caus global warm -sarcast republ...  \n",
       "...                                                  ...  \n",
       "10541  brb write poem climat chang climatechang scien...  \n",
       "10542  2016 year climat chang came home dure hottest ...  \n",
       "10543  pacif countri posit fiji lead global climat ch...  \n",
       "10544          hot must caus global warm aldublaboroflov  \n",
       "10545  climat chang global issu onli get wors eat pla...  \n",
       "\n",
       "[10546 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(test1['cleaned message'])\n",
    "y_test_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment']=y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>RT @BrittanyBohrer: Brb, writing a poem about ...</td>\n",
       "      <td>895714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>2016: the year climate change came home: Durin...</td>\n",
       "      <td>875167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>RT @loop_vanuatu: Pacific countries positive a...</td>\n",
       "      <td>78329</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>RT @xanria_00018: You’re so hot, you must be t...</td>\n",
       "      <td>867455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>RT @chloebalaoing: climate change is a global ...</td>\n",
       "      <td>470892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  tweetid  sentiment\n",
       "0      Europe will now be looking to China to make su...   169760          1\n",
       "1      Combine this with the polling of staffers re c...    35326          0\n",
       "2      The scary, unimpeachable evidence that climate...   224985          1\n",
       "3      @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263          1\n",
       "4      RT @FakeWillMoore: 'Female orgasms cause globa...   872928          0\n",
       "...                                                  ...      ...        ...\n",
       "10541  RT @BrittanyBohrer: Brb, writing a poem about ...   895714          1\n",
       "10542  2016: the year climate change came home: Durin...   875167          1\n",
       "10543  RT @loop_vanuatu: Pacific countries positive a...    78329          2\n",
       "10544  RT @xanria_00018: You’re so hot, you must be t...   867455          0\n",
       "10545  RT @chloebalaoing: climate change is a global ...   470892          1\n",
       "\n",
       "[10546 rows x 3 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['tweetid','sentiment']].to_csv('testsubmission13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
